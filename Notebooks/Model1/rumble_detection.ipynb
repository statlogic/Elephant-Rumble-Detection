{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "eYXzo-MKN0Dx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import decimal\n",
    "import math\n",
    "from scipy.fftpack import dct\n",
    "from scipy.signal.windows import hann\n",
    "import librosa\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "pv7R0hkxN9Zv"
   },
   "outputs": [],
   "source": [
    "# Round function\n",
    "def round_half_up(number):\n",
    "  return int(decimal.Decimal(number).quantize(decimal.Decimal('1'), rounding=decimal.ROUND_HALF_UP))\n",
    "\n",
    "# Return necessary variables to correlate Greenwood scale with Hertz\n",
    "def returnValueTuple():\n",
    "  fmin = 14\n",
    "  fmax = 12000\n",
    "  k = 0.88\n",
    "  A = fmin/(1-k)\n",
    "  a = math.log10(fmax/A+k)\n",
    "  return (a,A,k)\n",
    "\n",
    "# Retreive Greenwood from Hertz\n",
    "def greenwood_from_hertz(hertz):\n",
    "  a,A,k = returnValueTuple()\n",
    "  f = hertz\n",
    "  return (1/a)*math.log10(f/A+k)\n",
    "\n",
    "# Retreive Hertz from Greenwood\n",
    "def hertz_from_greenwood(greenwood):\n",
    "  a,A,k = returnValueTuple()\n",
    "  fp = greenwood\n",
    "  return A*(10**(a*fp)-k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NFFT: The size of FFT, It FFT number is less the precision will be less because of dropping many samples; \n",
    "#       Using large FFT allows zero padding which is neutral when frequency domain is concerened\n",
    "#       Here Multiplication by 2 is done which allows some padding but is safe as no sample are dropped \n",
    "def calculateNFFTS(sampleRate,windowLength):\n",
    "  windowLengthSample = windowLength*sampleRate\n",
    "  nfft = 1\n",
    "  while nfft < windowLengthSample:\n",
    "    nfft*=2\n",
    "  return nfft\n",
    "\n",
    "# Pre Emphasis: Amplification of high frequencies to balance the frequency spectrum as high frequencies tend to have low magnitude when compared to lower ones\n",
    "# Formula: x`(n) = x(n) - a*x(n-1) where a = pre-emphasis factor\n",
    "def preEmphasis(signal,preEmphasisFactor=0.97):\n",
    "  return np.append(signal[0], signal[1:] - preEmphasisFactor * signal[:-1])\n",
    "\n",
    "# Numpy stride technique, refer: \n",
    "# https://ellisvalentiner.com/post/np-strides-trick/ and\n",
    "# https://ipython-books.github.io/46-using-stride-tricks-with-numpy/\n",
    "def rollingWindow(paddedSignal,frameLength,step=1):\n",
    "    shape = paddedSignal.shape[:-1] + (paddedSignal.shape[-1] - frameLength + 1, frameLength)\n",
    "    strides = paddedSignal.strides + (paddedSignal.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(paddedSignal, shape=shape, strides=strides)[::step]\n",
    "\n",
    "# Cut the signal in frames, frameStep = Number of frames of previous sample after which 2nd sample frames should start, strideTrick uses internal numpy method\n",
    "def frameSignal(signal, frameLength, frameStep, windowFunction):\n",
    "\n",
    "  lengthOfSignal = len(signal)\n",
    "  frameLength = int(round_half_up(frameLength))\n",
    "  frameStep = int(round_half_up(frameStep))\n",
    "\n",
    "  if lengthOfSignal < frameLength:\n",
    "    numberOfFrames = 1\n",
    "  else:\n",
    "    numberOfFrames = 1 + int(math.ceil((1.0 * lengthOfSignal - frameLength) / frameStep))\n",
    "\n",
    "  paddingLength = int((numberOfFrames - 1) * frameStep + frameLength)\n",
    "  zeros = np.zeros((paddingLength - lengthOfSignal,))\n",
    "  paddedsignal = np.concatenate((signal, zeros))\n",
    "\n",
    "  # Use numpy to efficiently make windows\n",
    "  window = windowFunction(frameLength)\n",
    "  frames = rollingWindow(paddedsignal,frameLength,step = frameStep)\n",
    "\n",
    "  return frames * window\n",
    "\n",
    "# Magnitude Spectrum: Calculated using numpy.fft.rfft' returns the absolute values after taking fourier transfrom\n",
    "def magSpectrum(frames,nfft):\n",
    "  if np.shape(frames)[1] > nfft:\n",
    "    logging.warn('frame length {} is greater than FFT size {}, frame will be truncated. Increase NFFT to avoid.'.format(np.shape(frames)[1],nfft))\n",
    "  complexSpectrum = np.fft.rfft(frames,nfft)\n",
    "  return np.absolute(complexSpectrum)\n",
    "\n",
    "# Power Spectrum: Calulated using 1/n*|si|^2 where 'si' is fourier transform\n",
    "def powSpectrum(frames,nfft):\n",
    "  return 1.0/nfft*np.square(magSpectrum(frames,nfft))\n",
    "\n",
    "# Log power spectrum and normalize: Not needed\n",
    "def logPowSpectrum(frames,nfft,normalize = 1):\n",
    "  powerSpectrum = powSpectrum(frames,nfft)\n",
    "  # If values are close to 0 or 0 log function will have problem\n",
    "  powerSpectrum[powerSpectrum<= 1e-30] = 1e-30\n",
    "  logPowerSpectrum = 10*np.log10(powerSpectrum)\n",
    "  if normalize:\n",
    "    return logPowerSpectrum - np.max(logPowerSpectrum)\n",
    "  else:\n",
    "    return logPowerSpectrum\n",
    "\n",
    "# Returns Filter Banks: \n",
    "# Filters correspond to rows and Columns correspond to fft bins\n",
    "# returns: array of size = numberOfFilter*(nfft/2+1)\n",
    "def returnFilterBanks(numberOfFilter=30,nfft=512,sampleRate=16000,lowFrequency=0,highFrequency=None):\n",
    "  highFrequency= highFrequency or sampleRate/2\n",
    "  assert highFrequency <= sampleRate/2, \"High Frequency is greater than sampleRate/2\"\n",
    "\n",
    "  # Calculate evenly spaced pts in greenwood\n",
    "  lowGreenWood = greenwood_from_hertz(lowFrequency)\n",
    "  highGreenWood = greenwood_from_hertz(highFrequency)\n",
    "  greenWoodPoints = np.linspace(lowGreenWood,highGreenWood,numberOfFilter+2)\n",
    "\n",
    "  # Current points are in Hertz, but we use fft bins, so we have to convert from Hertz to fft bin number\n",
    "  bin = np.floor((nfft+1)*hertz_from_greenwood(greenWoodPoints)/sampleRate)\n",
    "\n",
    "  fbank = np.zeros([numberOfFilter,nfft//2+1])\n",
    "  for j in range(0,numberOfFilter):\n",
    "      for i in range(int(bin[j]), int(bin[j+1])):\n",
    "          fbank[j,i] = (i - bin[j]) / (bin[j+1]-bin[j])\n",
    "      for i in range(int(bin[j+1]), int(bin[j+2])):\n",
    "          fbank[j,i] = (bin[j+2]-i) / (bin[j+2]-bin[j+1])\n",
    "  return fbank\n",
    "\n",
    "# Array of banpass filters(filters which decide what frequencies can pass)\n",
    "def filterBank(signal,sampleRate=16000, windowLength=0.025, windowStep=0.01, numberOfFilter=30, nfft=512,\n",
    "               lowFrequency=0, highFrequency=None, preEmphasisFactor=0.97, windowFunction=lambda x: np.ones((x,))):\n",
    "  \n",
    "  highFrequency = highFrequency or sampleRate/2\n",
    "  \n",
    "  # Step 1: Apply pre emphasis on signal\n",
    "  signal = preEmphasis(signal,preEmphasisFactor)\n",
    "\n",
    "  # Step 2: Frame a signal to overlapping signals: 2d nd array\n",
    "  frames = frameSignal(signal, windowLength*sampleRate, windowStep*sampleRate, windowFunction)\n",
    "\n",
    "  # Step 3: Calculate the power spectrum\n",
    "  powerSpec = powSpectrum(frames,nfft)\n",
    "  \n",
    "  # Step 4: Calculate the total energy in each frame\n",
    "  energy = np.sum(powerSpec,1)\n",
    "  energy = np.where(energy==0,np.finfo(float).eps,energy)\n",
    "\n",
    "  # Step 5: Get Filter Banks and its energy\n",
    "  filterBank = returnFilterBanks(numberOfFilter,nfft,sampleRate,lowFrequency,highFrequency)\n",
    "  features = np.dot(powerSpec,filterBank.T)\n",
    "  features = np.where(features==0,np.finfo(float).eps,features)\n",
    "\n",
    "  return features,energy\n",
    "\n",
    "# Apply Sinosoidal liftering: Increases the magnitude of highFrequency DCT coefficients\n",
    "# To de-emphasize higher MFCCs which has been claimed to improve audio detection under noisy circumstances \n",
    "def lifter(cepstra,lifterParameter=22):\n",
    "  L = lifterParameter\n",
    "  if L > 0:\n",
    "    nframes,ncoeff = np.shape(cepstra)\n",
    "    n = np.arange(ncoeff)\n",
    "    lift = 1 + (L/2.)*np.sin(np.pi*n/L)\n",
    "    return lift*cepstra\n",
    "  else:\n",
    "    return cepstra # No liftering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gfcc(signal,sampleRate = 16000, windowLength = 0.025, windowStep = 0.01, returnCepstrumNumber = 13, \n",
    "         numberOfFilter = 30, nfft = None, lowFrequency = 0, highFrequency = None, preEmphasisFactor = 0.97, \n",
    "         lifterParameter = 22, appendEnergy = True, windowFunction = lambda x: np.ones((x,))):\n",
    "  \n",
    "  # Step 1: Calculate the length of analysis window\n",
    "  nfft = nfft or calculateNFFTS(sampleRate,windowLength)\n",
    "\n",
    "  # Step 2 + 3: Calculate Greenwood Filter Bank and apply to power spectrum\n",
    "  features, energy = filterBank(signal,sampleRate, windowLength,windowStep, numberOfFilter, nfft, lowFrequency, highFrequency, preEmphasisFactor, windowFunction)\n",
    "\n",
    "  # Step 4: Take log of features\n",
    "  features = np.log(features)\n",
    "\n",
    "  # Step 5: Take discrete fourier transform\n",
    "  features = dct(features,axis=1,norm='ortho')[:,:returnCepstrumNumber]\n",
    "\n",
    "  # Step 6: Liftering\n",
    "  features = lifter(features,lifterParameter)\n",
    "\n",
    "  # First frame generally defines energy of that frame\n",
    "  if appendEnergy:\n",
    "    features[:,0] = np.log(energy)\n",
    "  \n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(file):\n",
    "  audio,sample_rate = librosa.load(file,res_type='kaiser_fast')\n",
    "  gfccs = gfcc(audio,sample_rate,windowFunction=hann,returnCepstrumNumber=18,preEmphasisFactor=0,lifterParameter=0)\n",
    "  gfcc_scaled_features = np.mean(gfccs,axis=0)\n",
    "  return gfcc_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = '../mubin/Data/Training'\n",
    "testing_data_path = '../mubin/Data/Testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted files\n",
    "\n",
    "for path in [testing_data_path,training_data_path]:\n",
    "    for folder in ['Noise','Rumbles']:\n",
    "        for file in ['.amlignore', '.amlignore.amltmp']:\n",
    "            if os.path.exists(path+'/'+folder+'/'+file):\n",
    "                os.remove(path+'/'+folder+'/'+file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "qYFFcxEPQUl6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3180\n",
      "3180\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "noiseFiles = next(os.walk(training_data_path+'/Noise'))[2]\n",
    "print(len(noiseFiles))\n",
    "\n",
    "rumbleFiles = next(os.walk(training_data_path+'/Rumbles'))[2]\n",
    "print(len(rumbleFiles))\n",
    "\n",
    "print(len(noiseFiles)==len(rumbleFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "3XaH5yn5pfMS"
   },
   "outputs": [],
   "source": [
    "noise_set_size = len(noiseFiles)\n",
    "rumble_set_size = len(rumbleFiles)\n",
    "\n",
    "noiseList = [['Noise/noise_'+str(i)+'.wav','noise'] for i in range(1,noise_set_size+1)]\n",
    "rumbleList = [['Rumbles/rumble_'+str(i)+'.wav','rumble'] for i in range(1,rumble_set_size+1)]\n",
    "finalList = noiseList+rumbleList\n",
    "\n",
    "train_df = pd.DataFrame(finalList, columns =['Filename', 'Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "ZGRYHvXmpR0j"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Noise/noise_1.wav</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noise/noise_2.wav</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Noise/noise_3.wav</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Noise/noise_4.wav</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Noise/noise_5.wav</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6355</th>\n",
       "      <td>Rumbles/rumble_3176.wav</td>\n",
       "      <td>rumble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356</th>\n",
       "      <td>Rumbles/rumble_3177.wav</td>\n",
       "      <td>rumble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>Rumbles/rumble_3178.wav</td>\n",
       "      <td>rumble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6358</th>\n",
       "      <td>Rumbles/rumble_3179.wav</td>\n",
       "      <td>rumble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6359</th>\n",
       "      <td>Rumbles/rumble_3180.wav</td>\n",
       "      <td>rumble</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6360 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Filename   Class\n",
       "0           Noise/noise_1.wav   noise\n",
       "1           Noise/noise_2.wav   noise\n",
       "2           Noise/noise_3.wav   noise\n",
       "3           Noise/noise_4.wav   noise\n",
       "4           Noise/noise_5.wav   noise\n",
       "...                       ...     ...\n",
       "6355  Rumbles/rumble_3176.wav  rumble\n",
       "6356  Rumbles/rumble_3177.wav  rumble\n",
       "6357  Rumbles/rumble_3178.wav  rumble\n",
       "6358  Rumbles/rumble_3179.wav  rumble\n",
       "6359  Rumbles/rumble_3180.wav  rumble\n",
       "\n",
       "[6360 rows x 2 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "  audio,sample_rate = librosa.load(file,res_type='kaiser_fast')\n",
    "  gfccs = gfcc(audio,sample_rate,windowFunction=hann,returnCepstrumNumber=18,lowFrequency=10)\n",
    "  gfcc_scaled_features = np.mean(gfccs,axis=0)\n",
    "  return gfcc_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6360it [09:45, 10.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "extracted_features=[]\n",
    "for index_num,row in tqdm(train_df.iterrows()):\n",
    "    file_name = training_data_path+'/'+row['Filename']\n",
    "    class_name = row['Class']\n",
    "    data = features_extractor(file_name)\n",
    "    extracted_features.append([data,class_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-2.7742346467415677, 11.197860893261826, -71....</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-2.686257586667402, 11.160884023039879, -72.1...</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-2.719486179571193, 10.724759885589451, -71.4...</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-2.7067643900422573, 11.015782689283833, -72....</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-2.6791133929473694, 11.318273084983144, -72....</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature  class\n",
       "0  [-2.7742346467415677, 11.197860893261826, -71....  noise\n",
       "1  [-2.686257586667402, 11.160884023039879, -72.1...  noise\n",
       "2  [-2.719486179571193, 10.724759885589451, -71.4...  noise\n",
       "3  [-2.7067643900422573, 11.015782689283833, -72....  noise\n",
       "4  [-2.6791133929473694, 11.318273084983144, -72....  noise"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder=LabelEncoder()\n",
    "y_train = to_categorical(labelencoder.fit_transform(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5088, 18) (5088, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = to_categorical(labelencoder.transform(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1272, 18) (1272, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "757\n",
      "757\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "noiseTestFiles = next(os.walk(testing_data_path+'/Noise'))[2]\n",
    "print(len(noiseTestFiles))\n",
    "\n",
    "rumbleTestFiles = next(os.walk(testing_data_path+'/Rumbles'))[2]\n",
    "print(len(rumbleTestFiles))\n",
    "\n",
    "print(len(noiseTestFiles)==len(rumbleTestFiles))\n",
    "\n",
    "noise_test_set_size = len(noiseTestFiles)\n",
    "rumble_test_set_size = len(rumbleTestFiles)\n",
    "\n",
    "noiseTestList = [['Noise/noise_'+str(i)+'.wav','noise'] for i in range(1,noise_test_set_size+1)]\n",
    "rumbleTestList = [['Rumbles/rumble_'+str(i)+'.wav','rumble'] for i in range(1,rumble_test_set_size+1)]\n",
    "finalTestList = noiseTestList+rumbleTestList\n",
    "\n",
    "test_df = pd.DataFrame(finalTestList, columns =['Filename', 'Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Noise/noise_1.wav</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noise/noise_2.wav</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Noise/noise_3.wav</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Noise/noise_4.wav</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Noise/noise_5.wav</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>Rumbles/rumble_753.wav</td>\n",
       "      <td>rumble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>Rumbles/rumble_754.wav</td>\n",
       "      <td>rumble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>Rumbles/rumble_755.wav</td>\n",
       "      <td>rumble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>Rumbles/rumble_756.wav</td>\n",
       "      <td>rumble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>Rumbles/rumble_757.wav</td>\n",
       "      <td>rumble</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1514 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Filename   Class\n",
       "0          Noise/noise_1.wav   noise\n",
       "1          Noise/noise_2.wav   noise\n",
       "2          Noise/noise_3.wav   noise\n",
       "3          Noise/noise_4.wav   noise\n",
       "4          Noise/noise_5.wav   noise\n",
       "...                      ...     ...\n",
       "1509  Rumbles/rumble_753.wav  rumble\n",
       "1510  Rumbles/rumble_754.wav  rumble\n",
       "1511  Rumbles/rumble_755.wav  rumble\n",
       "1512  Rumbles/rumble_756.wav  rumble\n",
       "1513  Rumbles/rumble_757.wav  rumble\n",
       "\n",
       "[1514 rows x 2 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1514it [02:18, 10.89it/s]\n"
     ]
    }
   ],
   "source": [
    "extracted_test_features=[]\n",
    "for index_num,row in tqdm(test_df.iterrows()):\n",
    "    file_name = testing_data_path+'/'+row['Filename']\n",
    "    class_name = row['Class']\n",
    "    data = features_extractor(file_name)\n",
    "    extracted_test_features.append([data,class_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-3.0797442981364695, 11.338257063850921, -73....</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-3.075741105588124, 11.108618808954224, -73.1...</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-3.0830289176104855, 11.181089276987564, -73....</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-2.938467449148092, 22.563418787639403, -79.6...</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-2.982341041721689, 22.745090798299028, -79.7...</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature  class\n",
       "0  [-3.0797442981364695, 11.338257063850921, -73....  noise\n",
       "1  [-3.075741105588124, 11.108618808954224, -73.1...  noise\n",
       "2  [-3.0830289176104855, 11.181089276987564, -73....  noise\n",
       "3  [-2.938467449148092, 22.563418787639403, -79.6...  noise\n",
       "4  [-2.982341041721689, 22.745090798299028, -79.7...  noise"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_test_features_df=pd.DataFrame(extracted_test_features,columns=['feature','class'])\n",
    "extracted_test_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.array(extracted_test_features_df['feature'].tolist())\n",
    "y_test=np.array(extracted_test_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(labelencoder.transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1514, 18) (1514, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 2\n",
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(18,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 100)               1900      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 42,402\n",
      "Trainable params: 42,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5088 samples, validate on 1272 samples\n",
      "Epoch 1/400\n",
      "4992/5088 [============================>.] - ETA: 0s - loss: 4.0454 - accuracy: 0.5621\n",
      "Epoch 00001: val_loss improved from inf to 0.60065, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 208us/sample - loss: 3.9989 - accuracy: 0.5621 - val_loss: 0.6007 - val_accuracy: 0.6997\n",
      "Epoch 2/400\n",
      "4288/5088 [========================>.....] - ETA: 0s - loss: 0.9518 - accuracy: 0.6005\n",
      "Epoch 00002: val_loss did not improve from 0.60065\n",
      "5088/5088 [==============================] - 0s 71us/sample - loss: 0.9209 - accuracy: 0.6012 - val_loss: 0.6093 - val_accuracy: 0.7248\n",
      "Epoch 3/400\n",
      "4480/5088 [=========================>....] - ETA: 0s - loss: 0.6488 - accuracy: 0.6674\n",
      "Epoch 00003: val_loss improved from 0.60065 to 0.59154, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 0s 97us/sample - loss: 0.6491 - accuracy: 0.6688 - val_loss: 0.5915 - val_accuracy: 0.7539\n",
      "Epoch 4/400\n",
      "4192/5088 [=======================>......] - ETA: 0s - loss: 0.5776 - accuracy: 0.7085\n",
      "Epoch 00004: val_loss improved from 0.59154 to 0.54982, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 134us/sample - loss: 0.5769 - accuracy: 0.7077 - val_loss: 0.5498 - val_accuracy: 0.7791\n",
      "Epoch 5/400\n",
      "4960/5088 [============================>.] - ETA: 0s - loss: 0.5532 - accuracy: 0.7300\n",
      "Epoch 00005: val_loss improved from 0.54982 to 0.51492, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 113us/sample - loss: 0.5533 - accuracy: 0.7309 - val_loss: 0.5149 - val_accuracy: 0.7657\n",
      "Epoch 6/400\n",
      "4352/5088 [========================>.....] - ETA: 0s - loss: 0.5061 - accuracy: 0.7622\n",
      "Epoch 00006: val_loss improved from 0.51492 to 0.47017, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 109us/sample - loss: 0.5044 - accuracy: 0.7669 - val_loss: 0.4702 - val_accuracy: 0.8019\n",
      "Epoch 7/400\n",
      "5024/5088 [============================>.] - ETA: 0s - loss: 0.4829 - accuracy: 0.7848\n",
      "Epoch 00007: val_loss improved from 0.47017 to 0.44343, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 125us/sample - loss: 0.4826 - accuracy: 0.7846 - val_loss: 0.4434 - val_accuracy: 0.7972\n",
      "Epoch 8/400\n",
      "4864/5088 [===========================>..] - ETA: 0s - loss: 0.4651 - accuracy: 0.7907\n",
      "Epoch 00008: val_loss improved from 0.44343 to 0.43042, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 99us/sample - loss: 0.4647 - accuracy: 0.7921 - val_loss: 0.4304 - val_accuracy: 0.8011\n",
      "Epoch 9/400\n",
      "4352/5088 [========================>.....] - ETA: 0s - loss: 0.4557 - accuracy: 0.7999\n",
      "Epoch 00009: val_loss improved from 0.43042 to 0.41911, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 100us/sample - loss: 0.4549 - accuracy: 0.8003 - val_loss: 0.4191 - val_accuracy: 0.8318\n",
      "Epoch 10/400\n",
      "4384/5088 [========================>.....] - ETA: 0s - loss: 0.4403 - accuracy: 0.8111\n",
      "Epoch 00010: val_loss improved from 0.41911 to 0.40920, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 99us/sample - loss: 0.4414 - accuracy: 0.8094 - val_loss: 0.4092 - val_accuracy: 0.8286\n",
      "Epoch 11/400\n",
      "4288/5088 [========================>.....] - ETA: 0s - loss: 0.4271 - accuracy: 0.8088\n",
      "Epoch 00011: val_loss improved from 0.40920 to 0.40810, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 98us/sample - loss: 0.4306 - accuracy: 0.8080 - val_loss: 0.4081 - val_accuracy: 0.8349\n",
      "Epoch 12/400\n",
      "4512/5088 [=========================>....] - ETA: 0s - loss: 0.4286 - accuracy: 0.8125\n",
      "Epoch 00012: val_loss improved from 0.40810 to 0.39812, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 0s 94us/sample - loss: 0.4335 - accuracy: 0.8109 - val_loss: 0.3981 - val_accuracy: 0.8349\n",
      "Epoch 13/400\n",
      "4928/5088 [============================>.] - ETA: 0s - loss: 0.4108 - accuracy: 0.8257\n",
      "Epoch 00013: val_loss improved from 0.39812 to 0.37532, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 104us/sample - loss: 0.4131 - accuracy: 0.8231 - val_loss: 0.3753 - val_accuracy: 0.8546\n",
      "Epoch 14/400\n",
      "4192/5088 [=======================>......] - ETA: 0s - loss: 0.4183 - accuracy: 0.8197\n",
      "Epoch 00014: val_loss improved from 0.37532 to 0.37106, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 103us/sample - loss: 0.4221 - accuracy: 0.8188 - val_loss: 0.3711 - val_accuracy: 0.8475\n",
      "Epoch 15/400\n",
      "4576/5088 [=========================>....] - ETA: 0s - loss: 0.3870 - accuracy: 0.8341\n",
      "Epoch 00015: val_loss improved from 0.37106 to 0.36229, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 111us/sample - loss: 0.3896 - accuracy: 0.8357 - val_loss: 0.3623 - val_accuracy: 0.8475\n",
      "Epoch 16/400\n",
      "4512/5088 [=========================>....] - ETA: 0s - loss: 0.3911 - accuracy: 0.8336\n",
      "Epoch 00016: val_loss improved from 0.36229 to 0.36104, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 107us/sample - loss: 0.3930 - accuracy: 0.8331 - val_loss: 0.3610 - val_accuracy: 0.8506\n",
      "Epoch 17/400\n",
      "4992/5088 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8387\n",
      "Epoch 00017: val_loss improved from 0.36104 to 0.35888, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 105us/sample - loss: 0.3872 - accuracy: 0.8390 - val_loss: 0.3589 - val_accuracy: 0.8530\n",
      "Epoch 18/400\n",
      "4480/5088 [=========================>....] - ETA: 0s - loss: 0.3802 - accuracy: 0.8408\n",
      "Epoch 00018: val_loss improved from 0.35888 to 0.35685, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 0s 93us/sample - loss: 0.3816 - accuracy: 0.8382 - val_loss: 0.3568 - val_accuracy: 0.8546\n",
      "Epoch 19/400\n",
      "4352/5088 [========================>.....] - ETA: 0s - loss: 0.3754 - accuracy: 0.8419\n",
      "Epoch 00019: val_loss improved from 0.35685 to 0.35307, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 102us/sample - loss: 0.3772 - accuracy: 0.8410 - val_loss: 0.3531 - val_accuracy: 0.8561\n",
      "Epoch 20/400\n",
      "4448/5088 [=========================>....] - ETA: 0s - loss: 0.3767 - accuracy: 0.8429\n",
      "Epoch 00020: val_loss improved from 0.35307 to 0.33395, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 103us/sample - loss: 0.3713 - accuracy: 0.8445 - val_loss: 0.3340 - val_accuracy: 0.8648\n",
      "Epoch 21/400\n",
      "4544/5088 [=========================>....] - ETA: 0s - loss: 0.3759 - accuracy: 0.8391\n",
      "Epoch 00021: val_loss did not improve from 0.33395\n",
      "5088/5088 [==============================] - 0s 67us/sample - loss: 0.3823 - accuracy: 0.8373 - val_loss: 0.3654 - val_accuracy: 0.8577\n",
      "Epoch 22/400\n",
      "4992/5088 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8401\n",
      "Epoch 00022: val_loss did not improve from 0.33395\n",
      "5088/5088 [==============================] - 0s 71us/sample - loss: 0.3897 - accuracy: 0.8392 - val_loss: 0.3487 - val_accuracy: 0.8648\n",
      "Epoch 23/400\n",
      "4160/5088 [=======================>......] - ETA: 0s - loss: 0.3859 - accuracy: 0.8373\n",
      "Epoch 00023: val_loss did not improve from 0.33395\n",
      "5088/5088 [==============================] - 0s 70us/sample - loss: 0.3805 - accuracy: 0.8390 - val_loss: 0.3411 - val_accuracy: 0.8577\n",
      "Epoch 24/400\n",
      "4416/5088 [=========================>....] - ETA: 0s - loss: 0.3556 - accuracy: 0.8496\n",
      "Epoch 00024: val_loss improved from 0.33395 to 0.31823, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 111us/sample - loss: 0.3524 - accuracy: 0.8516 - val_loss: 0.3182 - val_accuracy: 0.8656\n",
      "Epoch 25/400\n",
      "4384/5088 [========================>.....] - ETA: 0s - loss: 0.3596 - accuracy: 0.8490\n",
      "Epoch 00025: val_loss did not improve from 0.31823\n",
      "5088/5088 [==============================] - 0s 73us/sample - loss: 0.3603 - accuracy: 0.8498 - val_loss: 0.3283 - val_accuracy: 0.8679\n",
      "Epoch 26/400\n",
      "4320/5088 [========================>.....] - ETA: 0s - loss: 0.3671 - accuracy: 0.8447\n",
      "Epoch 00026: val_loss did not improve from 0.31823\n",
      "5088/5088 [==============================] - 0s 74us/sample - loss: 0.3645 - accuracy: 0.8449 - val_loss: 0.3213 - val_accuracy: 0.8742\n",
      "Epoch 27/400\n",
      "4256/5088 [========================>.....] - ETA: 0s - loss: 0.3545 - accuracy: 0.8590\n",
      "Epoch 00027: val_loss did not improve from 0.31823\n",
      "5088/5088 [==============================] - 0s 69us/sample - loss: 0.3570 - accuracy: 0.8550 - val_loss: 0.3201 - val_accuracy: 0.8656\n",
      "Epoch 28/400\n",
      "4352/5088 [========================>.....] - ETA: 0s - loss: 0.3497 - accuracy: 0.8594\n",
      "Epoch 00028: val_loss did not improve from 0.31823\n",
      "5088/5088 [==============================] - 0s 69us/sample - loss: 0.3504 - accuracy: 0.8575 - val_loss: 0.3335 - val_accuracy: 0.8577\n",
      "Epoch 29/400\n",
      "4544/5088 [=========================>....] - ETA: 0s - loss: 0.3491 - accuracy: 0.8548\n",
      "Epoch 00029: val_loss did not improve from 0.31823\n",
      "5088/5088 [==============================] - 0s 68us/sample - loss: 0.3524 - accuracy: 0.8536 - val_loss: 0.3258 - val_accuracy: 0.8734\n",
      "Epoch 30/400\n",
      "4448/5088 [=========================>....] - ETA: 0s - loss: 0.3482 - accuracy: 0.8541\n",
      "Epoch 00030: val_loss did not improve from 0.31823\n",
      "5088/5088 [==============================] - 0s 69us/sample - loss: 0.3487 - accuracy: 0.8522 - val_loss: 0.3260 - val_accuracy: 0.8585\n",
      "Epoch 31/400\n",
      "4352/5088 [========================>.....] - ETA: 0s - loss: 0.3450 - accuracy: 0.8568\n",
      "Epoch 00031: val_loss improved from 0.31823 to 0.30481, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 0s 98us/sample - loss: 0.3525 - accuracy: 0.8500 - val_loss: 0.3048 - val_accuracy: 0.8821\n",
      "Epoch 32/400\n",
      "4416/5088 [=========================>....] - ETA: 0s - loss: 0.3560 - accuracy: 0.8474\n",
      "Epoch 00032: val_loss did not improve from 0.30481\n",
      "5088/5088 [==============================] - 0s 68us/sample - loss: 0.3457 - accuracy: 0.8524 - val_loss: 0.3116 - val_accuracy: 0.8719\n",
      "Epoch 33/400\n",
      "5056/5088 [============================>.] - ETA: 0s - loss: 0.3416 - accuracy: 0.8586\n",
      "Epoch 00033: val_loss improved from 0.30481 to 0.30014, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 115us/sample - loss: 0.3414 - accuracy: 0.8587 - val_loss: 0.3001 - val_accuracy: 0.8836\n",
      "Epoch 34/400\n",
      "4672/5088 [==========================>...] - ETA: 0s - loss: 0.3288 - accuracy: 0.8643\n",
      "Epoch 00034: val_loss did not improve from 0.30014\n",
      "5088/5088 [==============================] - 0s 65us/sample - loss: 0.3309 - accuracy: 0.8652 - val_loss: 0.3002 - val_accuracy: 0.8789\n",
      "Epoch 35/400\n",
      "4288/5088 [========================>.....] - ETA: 0s - loss: 0.3339 - accuracy: 0.8682\n",
      "Epoch 00035: val_loss did not improve from 0.30014\n",
      "5088/5088 [==============================] - 0s 69us/sample - loss: 0.3309 - accuracy: 0.8703 - val_loss: 0.3131 - val_accuracy: 0.8695\n",
      "Epoch 36/400\n",
      "4640/5088 [==========================>...] - ETA: 0s - loss: 0.3620 - accuracy: 0.8498\n",
      "Epoch 00036: val_loss did not improve from 0.30014\n",
      "5088/5088 [==============================] - 0s 65us/sample - loss: 0.3621 - accuracy: 0.8500 - val_loss: 0.3094 - val_accuracy: 0.8821\n",
      "Epoch 37/400\n",
      "4608/5088 [==========================>...] - ETA: 0s - loss: 0.3328 - accuracy: 0.8657\n",
      "Epoch 00037: val_loss did not improve from 0.30014\n",
      "5088/5088 [==============================] - 0s 66us/sample - loss: 0.3323 - accuracy: 0.8650 - val_loss: 0.3286 - val_accuracy: 0.8703\n",
      "Epoch 38/400\n",
      "4736/5088 [==========================>...] - ETA: 0s - loss: 0.3248 - accuracy: 0.8682\n",
      "Epoch 00038: val_loss improved from 0.30014 to 0.29972, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 107us/sample - loss: 0.3257 - accuracy: 0.8681 - val_loss: 0.2997 - val_accuracy: 0.8813\n",
      "Epoch 39/400\n",
      "4928/5088 [============================>.] - ETA: 0s - loss: 0.3335 - accuracy: 0.8622\n",
      "Epoch 00039: val_loss did not improve from 0.29972\n",
      "5088/5088 [==============================] - 0s 73us/sample - loss: 0.3324 - accuracy: 0.8624 - val_loss: 0.3100 - val_accuracy: 0.8726\n",
      "Epoch 40/400\n",
      "4320/5088 [========================>.....] - ETA: 0s - loss: 0.3234 - accuracy: 0.8692\n",
      "Epoch 00040: val_loss did not improve from 0.29972\n",
      "5088/5088 [==============================] - 0s 70us/sample - loss: 0.3256 - accuracy: 0.8677 - val_loss: 0.3146 - val_accuracy: 0.8789\n",
      "Epoch 41/400\n",
      "5024/5088 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.8609\n",
      "Epoch 00041: val_loss did not improve from 0.29972\n",
      "5088/5088 [==============================] - 0s 74us/sample - loss: 0.3399 - accuracy: 0.8608 - val_loss: 0.3037 - val_accuracy: 0.8813\n",
      "Epoch 42/400\n",
      "4544/5088 [=========================>....] - ETA: 0s - loss: 0.3351 - accuracy: 0.8620\n",
      "Epoch 00042: val_loss improved from 0.29972 to 0.29176, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 106us/sample - loss: 0.3337 - accuracy: 0.8636 - val_loss: 0.2918 - val_accuracy: 0.8852\n",
      "Epoch 43/400\n",
      "4896/5088 [===========================>..] - ETA: 0s - loss: 0.3259 - accuracy: 0.8672\n",
      "Epoch 00043: val_loss did not improve from 0.29176\n",
      "5088/5088 [==============================] - 0s 73us/sample - loss: 0.3258 - accuracy: 0.8665 - val_loss: 0.3013 - val_accuracy: 0.8766\n",
      "Epoch 44/400\n",
      "4352/5088 [========================>.....] - ETA: 0s - loss: 0.3170 - accuracy: 0.8732\n",
      "Epoch 00044: val_loss improved from 0.29176 to 0.28968, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 98us/sample - loss: 0.3168 - accuracy: 0.8732 - val_loss: 0.2897 - val_accuracy: 0.8844\n",
      "Epoch 45/400\n",
      "4704/5088 [==========================>...] - ETA: 0s - loss: 0.3220 - accuracy: 0.8744\n",
      "Epoch 00045: val_loss did not improve from 0.28968\n",
      "5088/5088 [==============================] - 0s 78us/sample - loss: 0.3226 - accuracy: 0.8722 - val_loss: 0.3013 - val_accuracy: 0.8797\n",
      "Epoch 46/400\n",
      "4576/5088 [=========================>....] - ETA: 0s - loss: 0.3096 - accuracy: 0.8737\n",
      "Epoch 00046: val_loss improved from 0.28968 to 0.28226, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 100us/sample - loss: 0.3108 - accuracy: 0.8732 - val_loss: 0.2823 - val_accuracy: 0.8931\n",
      "Epoch 47/400\n",
      "4672/5088 [==========================>...] - ETA: 0s - loss: 0.3092 - accuracy: 0.8761\n",
      "Epoch 00047: val_loss improved from 0.28226 to 0.26995, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 116us/sample - loss: 0.3072 - accuracy: 0.8772 - val_loss: 0.2700 - val_accuracy: 0.9009\n",
      "Epoch 48/400\n",
      "4480/5088 [=========================>....] - ETA: 0s - loss: 0.3243 - accuracy: 0.8687\n",
      "Epoch 00048: val_loss did not improve from 0.26995\n",
      "5088/5088 [==============================] - 0s 68us/sample - loss: 0.3271 - accuracy: 0.8681 - val_loss: 0.2879 - val_accuracy: 0.8844\n",
      "Epoch 49/400\n",
      "5056/5088 [============================>.] - ETA: 0s - loss: 0.3143 - accuracy: 0.8705\n",
      "Epoch 00049: val_loss did not improve from 0.26995\n",
      "5088/5088 [==============================] - 0s 73us/sample - loss: 0.3140 - accuracy: 0.8703 - val_loss: 0.2725 - val_accuracy: 0.9002\n",
      "Epoch 50/400\n",
      "4192/5088 [=======================>......] - ETA: 0s - loss: 0.3293 - accuracy: 0.8726\n",
      "Epoch 00050: val_loss did not improve from 0.26995\n",
      "5088/5088 [==============================] - 0s 70us/sample - loss: 0.3324 - accuracy: 0.8695 - val_loss: 0.2772 - val_accuracy: 0.9002\n",
      "Epoch 51/400\n",
      "4928/5088 [============================>.] - ETA: 0s - loss: 0.3107 - accuracy: 0.8774\n",
      "Epoch 00051: val_loss improved from 0.26995 to 0.26132, saving model to saved_models/rumble_classification.hdf5\n",
      "5088/5088 [==============================] - 1s 120us/sample - loss: 0.3092 - accuracy: 0.8778 - val_loss: 0.2613 - val_accuracy: 0.9025\n",
      "Epoch 52/400\n",
      "4288/5088 [========================>.....] - ETA: 0s - loss: 0.3140 - accuracy: 0.8741\n",
      "Epoch 00052: val_loss did not improve from 0.26132\n",
      "5088/5088 [==============================] - 0s 70us/sample - loss: 0.3117 - accuracy: 0.8758 - val_loss: 0.2716 - val_accuracy: 0.8962\n",
      "Epoch 53/400\n",
      "4512/5088 [=========================>....] - ETA: 0s - loss: 0.3166 - accuracy: 0.8679\n",
      "Epoch 00053: val_loss did not improve from 0.26132\n",
      "5088/5088 [==============================] - 0s 69us/sample - loss: 0.3139 - accuracy: 0.8693 - val_loss: 0.2786 - val_accuracy: 0.9002\n",
      "Epoch 54/400\n",
      "4544/5088 [=========================>....] - ETA: 0s - loss: 0.3205 - accuracy: 0.8691\n",
      "Epoch 00054: val_loss did not improve from 0.26132\n",
      "5088/5088 [==============================] - 0s 66us/sample - loss: 0.3262 - accuracy: 0.8669 - val_loss: 0.2895 - val_accuracy: 0.9057\n",
      "Epoch 55/400\n",
      "4768/5088 [===========================>..] - ETA: 0s - loss: 0.3121 - accuracy: 0.8737\n",
      "Epoch 00055: val_loss did not improve from 0.26132\n",
      "5088/5088 [==============================] - 0s 65us/sample - loss: 0.3139 - accuracy: 0.8721 - val_loss: 0.2842 - val_accuracy: 0.9002\n",
      "Epoch 56/400\n",
      "4736/5088 [==========================>...] - ETA: 0s - loss: 0.2960 - accuracy: 0.8851\n",
      "Epoch 00056: val_loss did not improve from 0.26132\n",
      "5088/5088 [==============================] - 0s 64us/sample - loss: 0.2986 - accuracy: 0.8846 - val_loss: 0.2632 - val_accuracy: 0.9049\n",
      "Epoch 57/400\n",
      "4768/5088 [===========================>..] - ETA: 0s - loss: 0.3027 - accuracy: 0.8790\n",
      "Epoch 00057: val_loss did not improve from 0.26132\n",
      "5088/5088 [==============================] - 0s 64us/sample - loss: 0.3052 - accuracy: 0.8770 - val_loss: 0.2875 - val_accuracy: 0.9002\n",
      "Epoch 58/400\n",
      "4256/5088 [========================>.....] - ETA: 0s - loss: 0.3041 - accuracy: 0.8825\n",
      "Epoch 00058: val_loss did not improve from 0.26132\n",
      "5088/5088 [==============================] - 0s 70us/sample - loss: 0.3090 - accuracy: 0.8805 - val_loss: 0.2871 - val_accuracy: 0.8892\n",
      "Epoch 59/400\n",
      "4224/5088 [=======================>......] - ETA: 0s - loss: 0.3077 - accuracy: 0.8807\n",
      "Epoch 00059: val_loss did not improve from 0.26132\n",
      "5088/5088 [==============================] - 0s 73us/sample - loss: 0.3110 - accuracy: 0.8778 - val_loss: 0.2772 - val_accuracy: 0.8962\n",
      "Epoch 60/400\n",
      "4320/5088 [========================>.....] - ETA: 0s - loss: 0.3143 - accuracy: 0.8752\n",
      "Epoch 00060: val_loss did not improve from 0.26132\n",
      "5088/5088 [==============================] - 0s 71us/sample - loss: 0.3170 - accuracy: 0.8724 - val_loss: 0.2783 - val_accuracy: 0.8821\n",
      "Epoch 61/400\n",
      "4352/5088 [========================>.....] - ETA: 0s - loss: 0.3265 - accuracy: 0.8674\n",
      "Epoch 00061: val_loss did not improve from 0.26132\n",
      "5088/5088 [==============================] - 0s 68us/sample - loss: 0.3223 - accuracy: 0.8687 - val_loss: 0.2699 - val_accuracy: 0.8954\n",
      "Training completed in time:  0:00:27.401704\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 400\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/rumble_classification.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "earlystopping = EarlyStopping(monitor =\"val_loss\", \n",
    "                                        mode =\"min\", patience = 10, \n",
    "                                        restore_best_weights = True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_val, y_val), callbacks=[checkpointer,earlystopping], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7212682\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(np.argmax(y_test,axis=-1), np.argmax(y_preds,axis=-1))\n",
    "p = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "plt.title('Confusion matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FinalGFCC.ipynb",
   "provenance": []
  },
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
