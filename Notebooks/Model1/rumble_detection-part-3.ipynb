{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "eYXzo-MKN0Dx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import decimal\n",
    "import math\n",
    "from scipy.fftpack import dct\n",
    "from scipy.signal.windows import hann\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pv7R0hkxN9Zv"
   },
   "outputs": [],
   "source": [
    "# Round function\n",
    "def round_half_up(number):\n",
    "  return int(decimal.Decimal(number).quantize(decimal.Decimal('1'), rounding=decimal.ROUND_HALF_UP))\n",
    "\n",
    "# Return necessary variables to correlate Greenwood scale with Hertz\n",
    "def returnValueTuple():\n",
    "  fmin = 10\n",
    "  fmax = 10000\n",
    "  k = 0.88\n",
    "  A = fmin/(1-k)\n",
    "  a = math.log10(fmax/A+k)\n",
    "  return (a,A,k)\n",
    "\n",
    "# Retreive Greenwood from Hertz\n",
    "def greenwood_from_hertz(hertz):\n",
    "  a,A,k = returnValueTuple()\n",
    "  f = hertz\n",
    "  return (1/a)*math.log10(f/A+k)\n",
    "\n",
    "# Retreive Hertz from Greenwood\n",
    "def hertz_from_greenwood(greenwood):\n",
    "  a,A,k = returnValueTuple()\n",
    "  fp = greenwood\n",
    "  return A*(10**(a*fp)-k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NFFT: The size of FFT, It FFT number is less the precision will be less because of dropping many samples; \n",
    "#       Using large FFT allows zero padding which is neutral when frequency domain is concerened\n",
    "#       Here Multiplication by 2 is done which allows some padding but is safe as no sample are dropped \n",
    "def calculateNFFTS(sampleRate,windowLength):\n",
    "  windowLengthSample = windowLength*sampleRate\n",
    "  nfft = 1\n",
    "  while nfft < windowLengthSample:\n",
    "    nfft*=2\n",
    "  return nfft\n",
    "\n",
    "# Pre Emphasis: Amplification of high frequencies to balance the frequency spectrum as high frequencies tend to have low magnitude when compared to lower ones\n",
    "# Formula: x`(n) = x(n) - a*x(n-1) where a = pre-emphasis factor\n",
    "def preEmphasis(signal,preEmphasisFactor=0.97):\n",
    "  return np.append(signal[0], signal[1:] - preEmphasisFactor * signal[:-1])\n",
    "\n",
    "# Numpy stride technique, refer: \n",
    "# https://ellisvalentiner.com/post/np-strides-trick/ and\n",
    "# https://ipython-books.github.io/46-using-stride-tricks-with-numpy/\n",
    "def rollingWindow(paddedSignal,frameLength,step=1):\n",
    "    shape = paddedSignal.shape[:-1] + (paddedSignal.shape[-1] - frameLength + 1, frameLength)\n",
    "    strides = paddedSignal.strides + (paddedSignal.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(paddedSignal, shape=shape, strides=strides)[::step]\n",
    "\n",
    "# Cut the signal in frames, frameStep = Number of frames of previous sample after which 2nd sample frames should start, strideTrick uses internal numpy method\n",
    "def frameSignal(signal, frameLength, frameStep, windowFunction):\n",
    "\n",
    "  lengthOfSignal = len(signal)\n",
    "  frameLength = int(round_half_up(frameLength))\n",
    "  frameStep = int(round_half_up(frameStep))\n",
    "\n",
    "  if lengthOfSignal < frameLength:\n",
    "    numberOfFrames = 1\n",
    "  else:\n",
    "    numberOfFrames = 1 + int(math.ceil((1.0 * lengthOfSignal - frameLength) / frameStep))\n",
    "\n",
    "  paddingLength = int((numberOfFrames - 1) * frameStep + frameLength)\n",
    "  zeros = np.zeros((paddingLength - lengthOfSignal,))\n",
    "  paddedsignal = np.concatenate((signal, zeros))\n",
    "\n",
    "  # Use numpy to efficiently make windows\n",
    "  window = windowFunction(frameLength)\n",
    "  frames = rollingWindow(paddedsignal,frameLength,step = frameStep)\n",
    "\n",
    "  return frames * window\n",
    "\n",
    "# Magnitude Spectrum: Calculated using numpy.fft.rfft' returns the absolute values after taking fourier transfrom\n",
    "def magSpectrum(frames,nfft):\n",
    "  if np.shape(frames)[1] > nfft:\n",
    "    logging.warn('frame length {} is greater than FFT size {}, frame will be truncated. Increase NFFT to avoid.'.format(np.shape(frames)[1],nfft))\n",
    "  complexSpectrum = np.fft.rfft(frames,nfft)\n",
    "  return np.absolute(complexSpectrum)\n",
    "\n",
    "# Power Spectrum: Calulated using 1/n*|si|^2 where 'si' is fourier transform\n",
    "def powSpectrum(frames,nfft):\n",
    "  return 1.0/nfft*np.square(magSpectrum(frames,nfft))\n",
    "\n",
    "# Log power spectrum and normalize: Not needed\n",
    "def logPowSpectrum(frames,nfft,normalize = 1):\n",
    "  powerSpectrum = powSpectrum(frames,nfft)\n",
    "  # If values are close to 0 or 0 log function will have problem\n",
    "  powerSpectrum[powerSpectrum<= 1e-30] = 1e-30\n",
    "  logPowerSpectrum = 10*np.log10(powerSpectrum)\n",
    "  if normalize:\n",
    "    return logPowerSpectrum - np.max(logPowerSpectrum)\n",
    "  else:\n",
    "    return logPowerSpectrum\n",
    "\n",
    "# Returns Filter Banks: \n",
    "# Filters correspond to rows and Columns correspond to fft bins\n",
    "# returns: array of size = numberOfFilter*(nfft/2+1)\n",
    "def returnFilterBanks(numberOfFilter=30,nfft=512,sampleRate=16000,lowFrequency=0,highFrequency=None):\n",
    "  highFrequency= highFrequency or sampleRate/2\n",
    "  assert highFrequency <= sampleRate/2, \"High Frequency is greater than sampleRate/2\"\n",
    "\n",
    "  # Calculate evenly spaced pts in greenwood\n",
    "  lowGreenWood = greenwood_from_hertz(lowFrequency)\n",
    "  highGreenWood = greenwood_from_hertz(highFrequency)\n",
    "  greenWoodPoints = np.linspace(lowGreenWood,highGreenWood,numberOfFilter+2)\n",
    "\n",
    "  # Current points are in Hertz, but we use fft bins, so we have to convert from Hertz to fft bin number\n",
    "  bin = np.floor((nfft+1)*hertz_from_greenwood(greenWoodPoints)/sampleRate)\n",
    "\n",
    "  fbank = np.zeros([numberOfFilter,nfft//2+1])\n",
    "  for j in range(0,numberOfFilter):\n",
    "      for i in range(int(bin[j]), int(bin[j+1])):\n",
    "          fbank[j,i] = (i - bin[j]) / (bin[j+1]-bin[j])\n",
    "      for i in range(int(bin[j+1]), int(bin[j+2])):\n",
    "          fbank[j,i] = (bin[j+2]-i) / (bin[j+2]-bin[j+1])\n",
    "  return fbank\n",
    "\n",
    "# Array of banpass filters(filters which decide what frequencies can pass)\n",
    "def filterBank(signal,sampleRate=16000, windowLength=0.025, windowStep=0.01, numberOfFilter=30, nfft=512,\n",
    "               lowFrequency=0, highFrequency=None, preEmphasisFactor=0.97, windowFunction=lambda x: np.ones((x,))):\n",
    "  \n",
    "  highFrequency = highFrequency or sampleRate/2\n",
    "  \n",
    "  # Step 1: Apply pre emphasis on signal\n",
    "  signal = preEmphasis(signal,preEmphasisFactor)\n",
    "\n",
    "  # Step 2: Frame a signal to overlapping signals: 2d nd array\n",
    "  frames = frameSignal(signal, windowLength*sampleRate, windowStep*sampleRate, windowFunction)\n",
    "\n",
    "  # Step 3: Calculate the power spectrum\n",
    "  powerSpec = powSpectrum(frames,nfft)\n",
    "  \n",
    "  # Step 4: Calculate the total energy in each frame\n",
    "  energy = np.sum(powerSpec,1)\n",
    "  energy = np.where(energy==0,np.finfo(float).eps,energy)\n",
    "\n",
    "  # Step 5: Get Filter Banks and its energy\n",
    "  filterBank = returnFilterBanks(numberOfFilter,nfft,sampleRate,lowFrequency,highFrequency)\n",
    "  features = np.dot(powerSpec,filterBank.T)\n",
    "  features = np.where(features==0,np.finfo(float).eps,features)\n",
    "\n",
    "  return features,energy\n",
    "\n",
    "# Apply Sinosoidal liftering: Increases the magnitude of highFrequency DCT coefficients\n",
    "# To de-emphasize higher MFCCs which has been claimed to improve audio detection under noisy circumstances \n",
    "def lifter(cepstra,lifterParameter=22):\n",
    "  L = lifterParameter\n",
    "  if L > 0:\n",
    "    nframes,ncoeff = np.shape(cepstra)\n",
    "    n = np.arange(ncoeff)\n",
    "    lift = 1 + (L/2.)*np.sin(np.pi*n/L)\n",
    "    return lift*cepstra\n",
    "  else:\n",
    "    return cepstra # No liftering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gfcc(signal,sampleRate = 16000, windowLength = 0.025, windowStep = 0.01, returnCepstrumNumber = 13, \n",
    "         numberOfFilter = 30, nfft = None, lowFrequency = 0, highFrequency = None, preEmphasisFactor = 0.97, \n",
    "         lifterParameter = 22, appendEnergy = True, windowFunction = lambda x: np.ones((x,))):\n",
    "  \n",
    "  # Step 1: Calculate the length of analysis window\n",
    "  nfft = nfft or calculateNFFTS(sampleRate,windowLength)\n",
    "\n",
    "  # Step 2 + 3: Calculate Greenwood Filter Bank and apply to power spectrum\n",
    "  features, energy = filterBank(signal,sampleRate, windowLength,windowStep, numberOfFilter, nfft, lowFrequency, highFrequency, preEmphasisFactor, windowFunction)\n",
    "\n",
    "  # Step 4: Take log of features\n",
    "  features = np.log(features)\n",
    "\n",
    "  # Step 5: Take discrete fourier transform\n",
    "  features = dct(features,axis=1,norm='ortho')[:,:returnCepstrumNumber]\n",
    "\n",
    "  # Step 6: Liftering\n",
    "  features = lifter(features,lifterParameter)\n",
    "\n",
    "  # First frame generally defines energy of that frame\n",
    "  if appendEnergy:\n",
    "    features[:,0] = np.log(energy)\n",
    "  \n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = '../mubin/Data/Training'\n",
    "testing_data_path = '../mubin/Data/Testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted files\n",
    "\n",
    "for path in [testing_data_path,training_data_path]:\n",
    "    for folder in ['Noise','Rumbles']:\n",
    "        for file in ['.amlignore', '.amlignore.amltmp']:\n",
    "            if os.path.exists(path+'/'+folder+'/'+file):\n",
    "                os.remove(path+'/'+folder+'/'+file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qYFFcxEPQUl6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3180\n",
      "3180\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "noiseFiles = next(os.walk(training_data_path+'/Noise'))[2]\n",
    "print(len(noiseFiles))\n",
    "\n",
    "rumbleFiles = next(os.walk(training_data_path+'/Rumbles'))[2]\n",
    "print(len(rumbleFiles))\n",
    "\n",
    "print(len(noiseFiles)==len(rumbleFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6360/6360 [10:32<00:00, 10.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# 4sec*2000 sr = 8000\n",
    "target = 8000\n",
    "targetSampleRate = 2000\n",
    "\n",
    "def returnGfccCoeff(audio,sample_rate):\n",
    "    gfccs = gfcc(audio,sample_rate,windowFunction=hann,returnCepstrumNumber=18,preEmphasisFactor=0,lifterParameter=0,lowFrequency=10,highFrequency=500,windowLength=0.075,windowStep=0.025)\n",
    "    return gfccs\n",
    "    \n",
    "def preProcess(fileName,ar,fileType):\n",
    "    audio,sample_rate = librosa.load(fileName,sr=targetSampleRate)\n",
    "    if len(audio)>=target:\n",
    "        newAudio = audio[:target]\n",
    "        ar.append([returnGfccCoeff(newAudio,targetSampleRate),fileType])\n",
    "    elif len(audio)>=4000:\n",
    "        newAudio = np.append(audio,np.zeros(target-len(audio)))\n",
    "        ar.append([returnGfccCoeff(newAudio,targetSampleRate),fileType])\n",
    "    \n",
    "noise_set_size = len(noiseFiles)\n",
    "rumble_set_size = len(rumbleFiles)\n",
    "noiseList = [['Noise/noise_'+str(i)+'.wav',0] for i in range(1,noise_set_size+1)]\n",
    "rumbleList = [['Rumbles/rumble_'+str(i)+'.wav',1] for i in range(1,rumble_set_size+1)]\n",
    "finalList = noiseList+rumbleList\n",
    "    \n",
    "preProcessedTrainFiles = []\n",
    "for i in tqdm(finalList):\n",
    "    filePath = i[0]\n",
    "    fileType = i[1]\n",
    "    fileName = training_data_path+'/'+filePath\n",
    "    preProcess(fileName,preProcessedTrainFiles,fileType)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-4.353478744308409, 8.847299193587524, 3.689...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-5.1132014529120475, 4.239382867939322, 0.93...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-4.634898580352101, 6.435720899107354, 4.121...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-4.912678649511506, 8.761000676590456, 2.236...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-4.104406307550257, 8.320791089854463, 3.938...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature  class\n",
       "0  [[-4.353478744308409, 8.847299193587524, 3.689...      0\n",
       "1  [[-5.1132014529120475, 4.239382867939322, 0.93...      0\n",
       "2  [[-4.634898580352101, 6.435720899107354, 4.121...      0\n",
       "3  [[-4.912678649511506, 8.761000676590456, 2.236...      0\n",
       "4  [[-4.104406307550257, 8.320791089854463, 3.938...      0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df=pd.DataFrame(preProcessedTrainFiles,columns=['feature','class'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158, 18)    6054\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df.apply(lambda row: row['feature'].shape,axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6054, 158, 18) (6054,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# labelencoder=LabelEncoder()\n",
    "# y_train = to_categorical(labelencoder.fit_transform(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4843, 158, 18) (4843,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_val = to_categorical(labelencoder.transform(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1211, 158, 18) (1211,)\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,X_train.shape[1],X_train.shape[2],1)\n",
    "\n",
    "X_val = X_val.reshape(-1,X_val.shape[1],X_val.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4843, 158, 18, 1) (4843,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1211, 158, 18, 1) (1211,)\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "757\n",
      "757\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "noiseTestFiles = next(os.walk(testing_data_path+'/Noise'))[2]\n",
    "print(len(noiseTestFiles))\n",
    "\n",
    "rumbleTestFiles = next(os.walk(testing_data_path+'/Rumbles'))[2]\n",
    "print(len(rumbleTestFiles))\n",
    "\n",
    "print(len(noiseTestFiles)==len(rumbleTestFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1514/1514 [02:23<00:00, 10.56it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "noise_test_set_size = len(noiseTestFiles)\n",
    "rumble_test_set_size = len(rumbleTestFiles)\n",
    "\n",
    "noiseTestList = [['Noise/noise_'+str(i)+'.wav',0] for i in range(1,noise_test_set_size+1)]\n",
    "rumbleTestList = [['Rumbles/rumble_'+str(i)+'.wav',1] for i in range(1,rumble_test_set_size+1)]\n",
    "\n",
    "finalTestList = noiseTestList+rumbleTestList\n",
    "    \n",
    "preProcessedTestFiles = []\n",
    "for i in tqdm(finalTestList):\n",
    "    filePath = i[0]\n",
    "    fileType = i[1]\n",
    "    fileName = testing_data_path+'/'+filePath\n",
    "    preProcess(fileName,preProcessedTestFiles,fileType)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-5.0897777786499985, 3.8598030465252444, 1.6...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-4.6996006670551616, 7.3385415086445285, 1.8...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-5.3567076987659465, 5.48035718638847, 5.174...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-3.577061882726914, 2.1885531707106054, 0.56...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-3.911528384184917, 0.6352179563304279, 0.77...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature  class\n",
       "0  [[-5.0897777786499985, 3.8598030465252444, 1.6...      0\n",
       "1  [[-4.6996006670551616, 7.3385415086445285, 1.8...      0\n",
       "2  [[-5.3567076987659465, 5.48035718638847, 5.174...      0\n",
       "3  [[-3.577061882726914, 2.1885531707106054, 0.56...      0\n",
       "4  [[-3.911528384184917, 0.6352179563304279, 0.77...      0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_test_features_df = pd.DataFrame(preProcessedTestFiles,columns=['feature','class'])\n",
    "extracted_test_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158, 18)    1462\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_test_features_df.apply(lambda row: row['feature'].shape,axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.array(extracted_test_features_df['feature'].tolist())\n",
    "y_test=np.array(extracted_test_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = to_categorical(labelencoder.transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(-1,X_test.shape[1],X_test.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1462, 158, 18, 1) (1462,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, input_shape=X_train.shape[1:] ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 156, 16, 64)       640       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 156, 16, 64)       256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 156, 16, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 78, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 76, 6, 32)         18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 76, 6, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 76, 6, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 38, 3, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3648)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                116768    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 136,417\n",
      "Trainable params: 136,161\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4843 samples, validate on 1211 samples\n",
      "Epoch 1/100\n",
      "4843/4843 [==============================] - 13s 3ms/sample - loss: 0.1792 - accuracy: 0.9393 - val_loss: 0.2300 - val_accuracy: 0.9604\n",
      "Epoch 2/100\n",
      "4843/4843 [==============================] - 12s 2ms/sample - loss: 0.0892 - accuracy: 0.9738 - val_loss: 0.1414 - val_accuracy: 0.9472\n",
      "Epoch 3/100\n",
      "4843/4843 [==============================] - 12s 2ms/sample - loss: 0.0637 - accuracy: 0.9827 - val_loss: 0.0861 - val_accuracy: 0.9727\n",
      "Epoch 4/100\n",
      "4843/4843 [==============================] - 12s 2ms/sample - loss: 0.0443 - accuracy: 0.9872 - val_loss: 0.3062 - val_accuracy: 0.9216\n",
      "Epoch 5/100\n",
      "4843/4843 [==============================] - 20s 4ms/sample - loss: 0.0268 - accuracy: 0.9938 - val_loss: 0.0921 - val_accuracy: 0.9711\n",
      "Epoch 6/100\n",
      "4843/4843 [==============================] - 20s 4ms/sample - loss: 0.0296 - accuracy: 0.9915 - val_loss: 0.4376 - val_accuracy: 0.9125\n",
      "Epoch 7/100\n",
      "4843/4843 [==============================] - 20s 4ms/sample - loss: 0.0184 - accuracy: 0.9955 - val_loss: 0.0915 - val_accuracy: 0.9612\n",
      "Epoch 8/100\n",
      "4843/4843 [==============================] - 20s 4ms/sample - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.1339 - val_accuracy: 0.9422\n",
      "Training completed in time:  0:02:06.570699\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "\n",
    "earlystopping = EarlyStopping(monitor =\"val_loss\", mode =\"min\", patience = 5, restore_best_weights = True)\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs,callbacks=[earlystopping], validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94391245\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08837481],\n",
       "       [0.00138085],\n",
       "       [0.02319771],\n",
       "       ...,\n",
       "       [0.22247593],\n",
       "       [0.97695667],\n",
       "       [0.16806886]], dtype=float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "y_preds = y_preds.ravel()\n",
    "y_predsCopy = copy.deepcopy(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08837481, 0.00138085, 0.02319771, ..., 0.22247593, 0.97695667,\n",
       "       0.16806886], dtype=float32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, predicted in enumerate(y_preds):\n",
    "    if predicted >= 0.45:\n",
    "        y_preds[i] = 1\n",
    "    else:\n",
    "        y_preds[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test,y_preds)\n",
    "p = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "plt.title('Confusion matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2742829\t0.07963225\t0.15416084\t0.40476352\t0.16475208\t0.33369458\t0.27135807\t0.37198845\t0.15812393\t0.003445824\t0.41762635\t0.39813715\t0.114097536\t0.03775068\t0.0667372\t0.00010670059\t0.0024348893\t0.21006943\t0.35622916\t0.079353906\t0.047483586\t0.3806984\t0.3687393\t0.43736675\t0.21376282\t0.27848136\t0.2639734\t0.33975077\t0.13510388\t0.42120498\t0.06046257\t0.15565032\t0.23499042\t0.3992322\t0.30454296\t0.4054947\t0.17409709\t0.20253353\t0.10266082\t0.340481\t0.1261971\t0.3644492\t0.20860822\t0.20210427\t0.34090954\t0.02563282\t0.440271\t0.18574414\t0.14915752\t0.2646743\t0.2049423\t0.119007304\t0.19675094\t0.16191126\t0.08933467\t0.053648923\t0.19655761\t0.42692906\t0.1967213\t0.3511195\t0.31432614\t0.05834043\t0.2033456\t0.03472584\t0.3421278\t0.15047456\t0.22247593\t0.16806886\t"
     ]
    }
   ],
   "source": [
    "for idx,val in enumerate(y_test):\n",
    "    if val == 1 and y_preds[idx]==0:\n",
    "        print(y_predsCopy[idx],end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       757\n",
      "           1       1.00      0.90      0.95       705\n",
      "\n",
      "    accuracy                           0.95      1462\n",
      "   macro avg       0.96      0.95      0.95      1462\n",
      "weighted avg       0.96      0.95      0.95      1462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSavingPath = 'saved_models/elephant_rumble_model_1.h5'\n",
    "if os.path.isfile(modelSavingPath) is False:\n",
    "    model.save(modelSavingPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelJsonSavingPath = 'saved_models/elephant_rumble_json_architecture_1.json'\n",
    "\n",
    "# serialize model to json\n",
    "json_model = model.to_json()\n",
    "\n",
    "#save the model architecture to JSON file\n",
    "with open(modelJsonSavingPath, 'w') as json_file:\n",
    "    json_file.write(json_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FinalGFCC.ipynb",
   "provenance": []
  },
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
